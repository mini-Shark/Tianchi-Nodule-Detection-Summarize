
# Rank 1
## 算法主要步骤#
- 候选结节位置提取
- FP Reduction 
- 结合肺内整体特征，对结节区域再次分类


![整体架构](/image/rank1_1.png)

### 1. 候选结节提取

主要利用FPN网络来做候选位置提取，使用FPN对原始图像滑窗，得出每个窗是否`包含`结节的概率和结节可能出现的位置，以及每个窗的特征（这里不清楚他用这个窗的特征来干什么）。这里他提到了在难例挖掘上用了focal loss，其实也就是mask-rcnn用的，因为FPN只是一个网络的部件结构，作者对比RPN，U-NET。所以说这里就不太清楚FPN的前面他到底用的是什么结构。再者，由于天池的数据没有mask,只有bbox，所以作者用的是检测框架

![FPN架构](/image/rank1_2.png)


### 2. FP Reduction

根据上一步提供的检测中心点，固定尺寸的提出图像块（因为显存优势，图像的分辨率略高，图像块略大）。然后输入到3DCNN中分类，这里分类模型主要是用了ResNet, DenseNet, SEnet。而且肯定都对他们做了一定修改（3D,计算速度等）

### 3. 结合肺内整体特征，对结节区域再次分类

*利用第二阶段3DCNN的深度特征，通过网络学习病例的整体特征，随后与结节自身的深度特征以及肺内统计信息Concat得到一个新的特征，输入分类器进行分类。*
原文如上所述，我猜他们应该是在上面的结果基础之上，又在结节区域附近区块，然后用上面的网络来提特征，租后加上原始结节位置的特征（也是来自于上面的CNN）然后利用肺内的统计信息来做最后的分类（这里的肺内统计信息不知道说的什么，pyradimioc里面的？不清楚）

![上下文网络架构](/image/rank1_3.png)

---

# Rank 2 
## 算法主要步骤
- 肺分割
- 提候选
- FP Reduction

![整体架构](/image/rank2_1.png)

## 1.分割
他的分割很有特点，只用了简单的图像学处理办法就得到很好的结果，比level set的方法优雅了很多。
主要有以下几个步骤：

- 原始输入图像二值化
- 填充肺腔，得到身体区域的mask
- 用上述mask掩模原始图像，这时身体以外的区域就被掩模成0了
- 再次进行二值化
- 对二值化结果进行形态学处理

他们这里用了一个比较优秀的判断分割结果的办法，就是以原始图像的Z轴序号为X轴，对应的图像mask面积为y轴绘制曲线，通过判断这条曲线是否是二次曲线来判断整个subject的分割效果,流程图如1所示

![肺分割示意](/image/rank2_2.png)


## 2.提候选
候选结节的提取主要还是用了有三次down-sample的UNET，在报告中他们提出几个比较重要的点
- 输入大小为48*48*48，采用same padding
- 保证结节在40*40*40的范围内，这就证明他们在选取正样本的时候，不仅仅只是用了以原始结节中心点选取的方式，还是有随机剪裁的方式或其他的东西
- 滑窗的大小24，输入的一半。在overlap的区域使用的是`max`操作


![UNET架构](/image/rank2_3.png)

## 3.FP Reduction
他们提到主要还是随机负样本不够丰富的原因，所以选择做了再次分类，输入大小是48*48*48。这里他们做的主要还是ensemble多个模型的输出，用了三个模型，再通过权重比例融合。三个模型分别是:

- resnet
- resnet+inception
- densenet

原报告提出几个重要的点：

- “多尺度：训练好48*48*48为输入的网络之后，采用36*36*36在原网络上finetune，不同视野大小对结节进行预测” 这里我觉得可能是在训练好3个48*48*48的分类网络之后，再对去掉后面的全连层进行finetune。对应于一个候选而言，在测试的时候可能是分别的提取48*48*48的块和36*36*36的块来进行测试。
- “hard negative mining `unet`的输出的候选，排除已经标注的true positive，其它的作为难例，渐进式的送到网络里。” 这说明在原始负样本的基础上，他们吧unet的负样本也加入进去训练了。
- “将 resnet，inception，densenet FC前一层的feature，feature个数分别为256，128，128，concat起来，尝试使用SVM,、RF、linear regression 再次训练一个假阳性衰减分类器，其中RF效果最好，与通过weight权重比例进行模型融合的方式结果差别不大”

![分类网络架构](/image/rank2_4.png)
